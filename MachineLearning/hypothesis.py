import json, os, re
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from typing import List, Dict, Any, TypedDict, Optional
from langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint
from langchain_community.graphs import Neo4jGraph
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.documents import Document
from langchain.chains.graph_qa.cypher import GraphCypherQAChain
from langchain_core.prompts import PromptTemplate

EMBEDDING_MODEL="sentence-transformers/all-mpnet-base-v2"
CHROMA_PERSIST_DIRECTORY="chroma_db"
CHROMA_COLLECTION_NAME="embed_storage"

NEO4J_URI=os.getenv('NEO4J_URI')
NEO4J_USERNAME=os.getenv('NEO4J_USERNAME')
NEO4J_PASSWORD=os.getenv('NEO4J_PASSWORD')

HUGGING_FACEHUB_MODEL="meta-llama/Llama-3.1-8b-instruct"
HGFC_API_TOKEN=os.getenv("HUGGINGFACEHUB_API_TOKEN")

embedding_function=HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)

vectordb=Chroma(collection_name=CHROMA_COLLECTION_NAME,embedding_function=embedding_function,persist_directory=CHROMA_PERSIST_DIRECTORY)

llm=HuggingFaceEndpoint(
    repo_id=HUGGING_FACEHUB_MODEL,
    temperature=0.7,
    max_new_tokens=512,
    huggingfacehub_api_token=HGFC_API_TOKEN
)

graph=Neo4jGraph(url=NEO4J_URI,username=NEO4J_USERNAME,password=NEO4J_PASSWORD)
graph.refresh_schema()

class Hypothesis(BaseModel):
    statement: str=Field(description="A concise and novel research hypothesis.")
    justification: str=Field(description="Brief explanation of why this hypothesis is plausible or important, based on the provided context.")
    relations: List[str]=Field(description="Key scientific concepts or entities related to the hypothesis.")
    potential_methods: List[str]=Field(description="Suggested experimental methods or approaches to test this hypothesis.")
    gaps_addressed: Optional[List[str]]=Field(default=None,description="Identified gaps in current research that this hypothesis addresses.")

class GraphState(TypedDict):
    """
    question: The user's query.
    vector_docs: List of documents retrieved from the vector database.
    graph_result: Structured data retrieved from the graph database.
    final_answer: The final answer generated by the LLM.
    messages: A list of messages to maintain conversation history (optional).
    """
    question: str
    vector_docs: List[Document]
    graph_result: str|dict
    final_answer: str

def retrieve_from_vector_db(state: GraphState)->GraphState:
    focus_area=state["focus_area"]
    retriever= vectordb.as_retriever(search_kwargs={"k": 10})
    vector_docs=retriever.invoke(focus_area)
    return {"vector_docs": vector_docs}

def query_neo4j_graph(state: GraphState)->GraphState:
    focus_area=state["focus_area"]
    graph_qa_chain=GraphCypherQAChain.from_llm(llm=llm,graph=graph,verbose=True)
    query_for_graph=f"What are the indirect and direct relationships between '{focus_area}' and research methods, concepts, or influential authors that could support hypothesis generation?"
    graph_result=graph_qa_chain.invoke({"query": query_for_graph})
    return {"graph_result": graph_result}

def generate_hypothesis(state: GraphState)->GraphState:
    focus_area=state["focus_area"]
    vector_db=state["vector_docs"]
    graph_result=state["graph_result"]

    vector_context="\n\n".join([doc.page_content for doc in vector_db])
    context=f"Vector Database Context:\n{vector_context}\n\nGraph Database Context:\n{graph_result}"

    hpt="""
    You are an expert AI researcher assistant. Your task is to generate ONE novel and plausible research hypothesis.
    The hypothesis should be based on the provided research paper contexts (Vector Database Context and Graph Database Context).
    Focus on identifying potential research gaps, unexplored connections between concepts, or novel applications of existing methods.

    Your output MUST be a JSON object that strictly adheres to the following Pydantic schema:
    ```json
    {{
        "hypothesis_statement": "string",
        "justification": "string",
        "related_concepts": ["string"],
        "potential_methods": ["string"],
        "gaps_addressed": ["string"]
    }}
    ```
    Ensure all fields are populated based on the context, or state "N/A" if no information is available.
    
    Focus Area: {focus_area}
    
    Combined Research Context:
    {full_context}
    
    Generate the hypothesis in JSON format:
    """

    prompt=PromptTemplate(
        input_variables=["focus_area", "full_context"],
        template=hpt
    )

    json_data=prompt
    json_data=json_data.invoke({"focus_area": focus_area, "full_context": context}).content
    parsed_hyp={}

    json_match=re.search(r"```json\n(.*)\n```",json_data,re.DOTALL)
    json_str=json_match.group(1) if json_match else json_data
    parsed_hyp=json.loads(json_str)
    return {"gen_hypothesis": parsed_hyp}

hypothesis_workflow = StateGraph(GraphState)
hypothesis_workflow.add_node("retrieve_vector_docs", retrieve_from_vector_db)
hypothesis_workflow.add_node("query_graph", query_neo4j_graph)
hypothesis_workflow.add_node("generate_hypothesis", generate_hypothesis)
hypothesis_workflow.add_edge(START, "retrieve_vector_docs")
hypothesis_workflow.add_edge("retrieve_vector_docs", "query_graph")
hypothesis_workflow.add_edge("query_graph", "generate_hypothesis")
hypothesis_workflow.add_edge("generate_hypothesis", END)
hypothesis_app = hypothesis_workflow.compile(checkpointer=MemorySaver())

if __name__ == "__main__":
    print("\n--- Starting PaperForge Hypothesis Generator ---")
    while True:
        focus_area_text = input("\nEnter a focus area for a new hypothesis (type 'exit' to quit): ").strip()
        if focus_area_text.lower() == 'exit':
            break
        if not focus_area_text:
            print("Please enter a focus area.")
            continue
        
        final_state = None
        for s in hypothesis_app.stream({"focus_area": focus_area_text}):
            final_state = s
        
        if final_state:
            generated_hypothesis_json = final_state[list(final_state.keys())[-1]]["generated_hypothesis"]
            print("\n=== GENERATED HYPOTHESIS ===")
            if generated_hypothesis_json and isinstance(generated_hypothesis_json, dict):
                print(json.dumps(generated_hypothesis_json, indent=2))
            else:
                print("Hypothesis generation failed or returned invalid JSON.")
                print(generated_hypothesis_json)